{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro-hw2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# <center><u> CP322: Assignment 1 – Winter 2023 </u> </center>\n",
    "# <center><u>  Due on  February 02, 2023 (Before 11:59 PM) </u> </center>\n",
    " \n",
    " This is an individual assignment, and we will practice the concepts to read, clean and explore the dataset, identifying the type of data collected, missing values, anomalies, exploring characteristics of individual variables. \n",
    " \n",
    " For this assignment, you must use Python language syntax. You will use this jupyter notebook to write your code without errors. You will be provided with a Makefile and instructions on using it. If your code does not run, then you will score zero. Therefore, ensure you have removed all syntax errors from your code. •\tGradescope platform would be used to upload the assignments for grading. The link to the Gradescope assignment is available on Myls course page. \n",
    " \n",
    " For submission, Drag and drop your code file(s) into Gradescope. Make sure that your file name should be as suggested in the assignment, using a different name may score zero.\n",
    " \n",
    " - Please note that the submitted code will be checked for plagiarism. By submitting this zip file, you would confirm that you have not received unauthorized assistance in preparing the assignment. You also confirm that you are aware of course policies for submitted work. \n",
    " \n",
    " - Marks will be deducted from any questions where these requirements are not met.\n",
    " \n",
    " - Multiple attempts will be allowed, but only your last submission before the deadline will be graded. Instructor reserves the right to take off points for not following the directions.\n",
    " \n",
    "<b>Warning:</b> Follow the assignment instructions to the letter in terms of the file names and function names, as this assignment will be auto-graded. If anything is not as per the description, the auto-grading fails, and your assignment will be given a Zero mark.\n",
    "\n",
    "Note: \n",
    "- For each question in the assignment, please write down your answer in the answer cell(s) right below the question. \n",
    "- It is helpful to have extra cells breaking down the process towards reaching your final answer. If you happen to create new cells below your answer to run codes, **NEVER** add cells between a question cell and the answer cell below it. It will cause errors when autograder run.\n",
    "- Finally, unless it is stated otherwise, try to avoid using python for loops or list comprehensions.  The majority of this part of assignment can be done using builtin commands in Pandas and numpy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Python Packages\n",
    "\n",
    "If any of the package is not available then install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)\n",
    "plt.style.use('fivethirtyeight')\n",
    "import os # Used to interact with the file system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "\n",
    "## Part 1: Cleaning and Exploring Data with Pandas\n",
    "## 1: Loading Data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Reading in the Files\n",
    "\n",
    "Use the following information and let's attempt to load `bus.csv` dataset, into pandas dataframe named `bus`.\n",
    "\n",
    "URL for loading the business data is: \n",
    "\n",
    "- \"https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/bus.csv\"\n",
    "\n",
    "**Note:** Because of character encoding issue with (`bus`) dataset, it will require an additional argument `encoding='ISO-8859-1'` when calling `pd.read_csv`. At some point in your future, you should read all about [character encodings](https://diveintopython3.problemsolving.io/strings.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bus = pd.read_csv(\"https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/bus.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've read in the file, let's try some `pd.DataFrame` methods ([docs](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.html)).\n",
    "Use the `DataFrame.head` method to show the top few lines of the `bus` dataframe. To show multiple return outputs in one single cell, you can use `display(EXPRESSION)`, change the EXPRESSION variable appropriately with code you want to show result/ouput for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business id column</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>HEUNG YUEN RESTAURANT</td>\n",
       "      <td>3279 22nd St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94110</td>\n",
       "      <td>37.755282</td>\n",
       "      <td>-122.420493</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100010</td>\n",
       "      <td>ILLY CAFFE SF_PIER 39</td>\n",
       "      <td>PIER 39  K-106-B</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94133</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14154827284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100017</td>\n",
       "      <td>AMICI'S EAST COAST PIZZERIA</td>\n",
       "      <td>475 06th St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94103</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14155279839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100026</td>\n",
       "      <td>LOCAL CATERING</td>\n",
       "      <td>1566 CARROLL AVE</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94124</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14155860315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100030</td>\n",
       "      <td>OUI OUI! MACARON</td>\n",
       "      <td>2200 JERROLD AVE STE C</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94124</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14159702675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business id column                         name                 address  \\\n",
       "0                1000        HEUNG YUEN RESTAURANT            3279 22nd St   \n",
       "1              100010        ILLY CAFFE SF_PIER 39        PIER 39  K-106-B   \n",
       "2              100017  AMICI'S EAST COAST PIZZERIA             475 06th St   \n",
       "3              100026               LOCAL CATERING        1566 CARROLL AVE   \n",
       "4              100030             OUI OUI! MACARON  2200 JERROLD AVE STE C   \n",
       "\n",
       "            city state postal_code     latitude    longitude  phone_number  \n",
       "0  San Francisco    CA       94110    37.755282  -122.420493         -9999  \n",
       "1  San Francisco    CA       94133 -9999.000000 -9999.000000   14154827284  \n",
       "2  San Francisco    CA       94103 -9999.000000 -9999.000000   14155279839  \n",
       "3  San Francisco    CA       94124 -9999.000000 -9999.000000   14155860315  \n",
       "4  San Francisco    CA       94124 -9999.000000 -9999.000000   14159702675  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame.describe` method can also be handy for computing summaries of numeric columns of our dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business id column</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6253.000000</td>\n",
       "      <td>6253.000000</td>\n",
       "      <td>6253.000000</td>\n",
       "      <td>6.253000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60448.948984</td>\n",
       "      <td>-5575.337966</td>\n",
       "      <td>-5645.817699</td>\n",
       "      <td>4.701819e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36480.132445</td>\n",
       "      <td>4983.390142</td>\n",
       "      <td>4903.993683</td>\n",
       "      <td>6.667508e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9.999000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18399.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9.999000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75685.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9.999000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90886.000000</td>\n",
       "      <td>37.776494</td>\n",
       "      <td>-122.421553</td>\n",
       "      <td>1.415533e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>102705.000000</td>\n",
       "      <td>37.824494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.415988e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       business id column     latitude    longitude  phone_number\n",
       "count         6253.000000  6253.000000  6253.000000  6.253000e+03\n",
       "mean         60448.948984 -5575.337966 -5645.817699  4.701819e+09\n",
       "std          36480.132445  4983.390142  4903.993683  6.667508e+09\n",
       "min             19.000000 -9999.000000 -9999.000000 -9.999000e+03\n",
       "25%          18399.000000 -9999.000000 -9999.000000 -9.999000e+03\n",
       "50%          75685.000000 -9999.000000 -9999.000000 -9.999000e+03\n",
       "75%          90886.000000    37.776494  -122.421553  1.415533e+10\n",
       "max         102705.000000    37.824494     0.000000  1.415988e+10"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "business-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 2: Examining the Business Data File\n",
    "\n",
    "From its name alone, it is expected that the `bus.csv` file to contain information about the restaurants. Let's investigate the granularity of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business id column</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>HEUNG YUEN RESTAURANT</td>\n",
       "      <td>3279 22nd St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94110</td>\n",
       "      <td>37.755282</td>\n",
       "      <td>-122.420493</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100010</td>\n",
       "      <td>ILLY CAFFE SF_PIER 39</td>\n",
       "      <td>PIER 39  K-106-B</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94133</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14154827284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100017</td>\n",
       "      <td>AMICI'S EAST COAST PIZZERIA</td>\n",
       "      <td>475 06th St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94103</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14155279839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100026</td>\n",
       "      <td>LOCAL CATERING</td>\n",
       "      <td>1566 CARROLL AVE</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94124</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14155860315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100030</td>\n",
       "      <td>OUI OUI! MACARON</td>\n",
       "      <td>2200 JERROLD AVE STE C</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94124</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14159702675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business id column                         name                 address  \\\n",
       "0                1000        HEUNG YUEN RESTAURANT            3279 22nd St   \n",
       "1              100010        ILLY CAFFE SF_PIER 39        PIER 39  K-106-B   \n",
       "2              100017  AMICI'S EAST COAST PIZZERIA             475 06th St   \n",
       "3              100026               LOCAL CATERING        1566 CARROLL AVE   \n",
       "4              100030             OUI OUI! MACARON  2200 JERROLD AVE STE C   \n",
       "\n",
       "            city state postal_code     latitude    longitude  phone_number  \n",
       "0  San Francisco    CA       94110    37.755282  -122.420493         -9999  \n",
       "1  San Francisco    CA       94133 -9999.000000 -9999.000000   14154827284  \n",
       "2  San Francisco    CA       94103 -9999.000000 -9999.000000   14155279839  \n",
       "3  San Francisco    CA       94124 -9999.000000 -9999.000000   14155860315  \n",
       "4  San Francisco    CA       94124 -9999.000000 -9999.000000   14159702675  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2a\n",
    "\n",
    "The `bus` dataframe contains a column called `business id column` which probably corresponds to a unique business id (also called `primary key`).  However, let's first rename that column to `bid`.  Modify the `bus` dataframe by renaming that column to `bid`.\n",
    "\n",
    "**Note**: In practice, you might want to do this renaming when the table is loaded but for grading purposes so let's do it here.\n",
    "\n",
    "Hint: Use DATAFRAME.rename(columns={\"OLD_NAME\": \"NEW_NAME\"}). Here, replace CAPITAL LETTERS appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>HEUNG YUEN RESTAURANT</td>\n",
       "      <td>3279 22nd St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94110</td>\n",
       "      <td>37.755282</td>\n",
       "      <td>-122.420493</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100010</td>\n",
       "      <td>ILLY CAFFE SF_PIER 39</td>\n",
       "      <td>PIER 39  K-106-B</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94133</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14154827284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100017</td>\n",
       "      <td>AMICI'S EAST COAST PIZZERIA</td>\n",
       "      <td>475 06th St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94103</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14155279839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100026</td>\n",
       "      <td>LOCAL CATERING</td>\n",
       "      <td>1566 CARROLL AVE</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94124</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14155860315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100030</td>\n",
       "      <td>OUI OUI! MACARON</td>\n",
       "      <td>2200 JERROLD AVE STE C</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94124</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14159702675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bid                         name                 address           city  \\\n",
       "0    1000        HEUNG YUEN RESTAURANT            3279 22nd St  San Francisco   \n",
       "1  100010        ILLY CAFFE SF_PIER 39        PIER 39  K-106-B  San Francisco   \n",
       "2  100017  AMICI'S EAST COAST PIZZERIA             475 06th St  San Francisco   \n",
       "3  100026               LOCAL CATERING        1566 CARROLL AVE  San Francisco   \n",
       "4  100030             OUI OUI! MACARON  2200 JERROLD AVE STE C  San Francisco   \n",
       "\n",
       "  state postal_code     latitude    longitude  phone_number  \n",
       "0    CA       94110    37.755282  -122.420493         -9999  \n",
       "1    CA       94133 -9999.000000 -9999.000000   14154827284  \n",
       "2    CA       94103 -9999.000000 -9999.000000   14155279839  \n",
       "3    CA       94124 -9999.000000 -9999.000000   14155860315  \n",
       "4    CA       94124 -9999.000000 -9999.000000   14159702675  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus = bus.rename(columns={\"business id column\": \"bid\"})\n",
    "bus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "Examining the entries in `bus`, is the `bid` unique for each record (i.e. each row of data)? Your code should compute the answer, i.e. don't just hard code `True` or `False`.\n",
    "\n",
    "Hint: use `value_counts()` or `unique()` to determine if the `bid` series has any duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-18T01:21:53.936572Z",
     "start_time": "2018-08-18T01:21:53.927344Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q2a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if len(bus.bid.unique()) == len(bus):\n",
    "    is_bid_unique = True\n",
    "else:\n",
    "    is_bid_unique = False\n",
    "print(is_bid_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2c\n",
    "\n",
    "In the two cells below create two **series** \n",
    "\n",
    "a) where the index is the `name` of the business and the value is the number of records with that `name`\n",
    "b) where the index is the `address` of the business and the value is the number of records with that `address`\n",
    "\n",
    "Order both series in descending order by count. You may need to use `value_counts()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Peet's Coffee & Tea                                       20\n",
       "Starbucks Coffee                                          13\n",
       "McDonald's                                                10\n",
       "Jamba Juice                                               10\n",
       "STARBUCKS                                                  9\n",
       "Proper Food                                                9\n",
       "Mixt Greens/Mixt                                           8\n",
       "Specialty's Cafe & Bakery                                  8\n",
       "Philz Coffee                                               7\n",
       "The Organic Coup                                           7\n",
       "Starbucks                                                  7\n",
       "Whole Foods Market                                         7\n",
       "Blue Bottle Coffee                                         7\n",
       "Bon Appetit @ Twitter                                      6\n",
       "Lee's Deli                                                 6\n",
       "BlueStar Refreshment Services @ Uber Technologies, Inc     6\n",
       "Annie's Hot Dogs & Pretzels                                5\n",
       "JW Marriott SF Union Square                                5\n",
       "STARBUCKS COFFEE                                           5\n",
       "PEET'S COFFEE & TEA                                        5\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part a) \n",
    "name_counts = bus.name.value_counts()\n",
    "name_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Off The Grid              39\n",
       "428 11th St               34\n",
       "2948 Folsom St            17\n",
       "3251 20th Ave             17\n",
       "Pier 41                   16\n",
       "103 Horne Ave             14\n",
       "24 Willie Mays Plaza      13\n",
       "Off the Grid              11\n",
       "1 United Nations Plaza    10\n",
       "2948 Folsom St.           10\n",
       "Name: address, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_counts = bus.address.value_counts()\n",
    "address_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "written"
    ]
   },
   "source": [
    "### Question 2d\n",
    "\n",
    "Based on the above calculations answer each of the following questions by filling the value in the variable.\n",
    "\n",
    "1. What does each record represent?  \n",
    "1. What is the minimal primary key?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does each record represent?  Valid answers are:\n",
    "#    \"One location of a restaurant.\"\n",
    "#    \"A chain of restaurants.\"\n",
    "#    \"A city block.\"\n",
    "q2d_part1 = \"One location of a restaurant.\"\n",
    "\n",
    "# What is the minimal primary key? Valid answers are:\n",
    "#    \"bid\"\n",
    "#    \"bid, name\"\n",
    "#    \"bid, name, address\"\n",
    "q2d_part2 = \"bid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "business-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## 3: Cleaning the Business Data Postal Codes\n",
    "\n",
    "The business data contains postal code information that can used to aggregate the ratings over regions of the city.  Let's examine and clean the postal code field.  The postal code (sometimes also called a ZIP code) partitions the city into regions:\n",
    "\n",
    "<img src=\"https://www.usmapguide.com/wp-content/uploads/2019/03/printable-san-francisco-zip-code-map.jpg\" alt=\"ZIP Code Map\" style=\"width: 600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4c4a09f1ecf2f4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3a\n",
    "\n",
    "How many restaurants are in each ZIP code? \n",
    "\n",
    "In the cell below, create a **series** where the index is the postal code and the value is the number of records with that postal code in descending order of count. You may need to use `groupby()`, `size()`, or `value_counts()`. Do you notice any odd/invalid zip codes?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2151d673e6c36a1",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94103         562\n",
      "94110         555\n",
      "94102         456\n",
      "94107         408\n",
      "94133         398\n",
      "94109         382\n",
      "94111         259\n",
      "94122         255\n",
      "94105         249\n",
      "94118         231\n",
      "94115         230\n",
      "94108         229\n",
      "94124         218\n",
      "94114         200\n",
      "-9999         194\n",
      "94112         192\n",
      "94117         189\n",
      "94123         177\n",
      "94121         157\n",
      "94104         142\n",
      "94132         132\n",
      "94116          97\n",
      "94158          90\n",
      "94134          82\n",
      "94127          67\n",
      "94131          49\n",
      "94130           8\n",
      "94143           5\n",
      "94301           2\n",
      "94188           2\n",
      "94101           2\n",
      "CA              2\n",
      "94013           2\n",
      "941102019       1\n",
      "941             1\n",
      "95112           1\n",
      "94105-2907      1\n",
      "94102-5917      1\n",
      "94124-1917      1\n",
      "94621           1\n",
      "95122           1\n",
      "95132           1\n",
      "95109           1\n",
      "95133           1\n",
      "95117           1\n",
      "94901           1\n",
      "94105-1420      1\n",
      "94544           1\n",
      "64110           1\n",
      "94122-1909      1\n",
      "00000           1\n",
      "94080           1\n",
      "Ca              1\n",
      "94602           1\n",
      "94129           1\n",
      "94014           1\n",
      "94117-3504      1\n",
      "94518           1\n",
      "94120           1\n",
      "92672           1\n",
      "95105           1\n",
      "941033148       1\n",
      "94123-3106      1\n"
     ]
    }
   ],
   "source": [
    "zip_counts = bus.postal_code.value_counts()\n",
    "print(zip_counts.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3b\n",
    "\n",
    "Answer the following questions about the `postal_code` column in the `bus` dataframe.\n",
    "\n",
    "1. The ZIP code column is which of the following type of data:\n",
    "    1. Quantitative Continuous\n",
    "    1. Quantitative Discrete\n",
    "    1. Qualitative Ordinal\n",
    "    1. Qualitative Nominal    \n",
    "1. What Python data type is used to represent a ZIP code?\n",
    "\n",
    "*Note*: ZIP codes and postal codes are the same thing.\n",
    "\n",
    "Please write your answers in the variables below:\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ZIP code column is which of the following type of data:\n",
    "#   \"Quantitative Continuous\" \n",
    "#   \"Quantitative Discrete\"\n",
    "#   \"Qualitative Ordinal\"\n",
    "#   \"Qualitative Nominal\"\n",
    "q3b_part1 = \"Quantitative Discrete\"\n",
    "\n",
    "# What Python data type is used to represent a ZIP code? \n",
    "#    \"str\"\n",
    "#    \"int\"\n",
    "#    \"bool\"\n",
    "#    \"float\"\n",
    "q3b_part2 = \"int\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3c\n",
    "\n",
    "In question 3a, a large number of potentially invalid ZIP codes exist (e.g., \"Ca\").  These are likely due to data entry errors.  To get a better understanding of the potential errors in the zip codes, do the following:\n",
    "\n",
    "1. Import a list of valid San Francisco ZIP codes by using `pd.read_json` (from URL = 'https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/sf_zipcodes.json') to load the file `sf_zipcodes.json` and extract a **series** of type `str` containing the valid ZIP codes.  \n",
    "\n",
    "*Hint: set `dtype` when invoking `read_json`.*\n",
    "\n",
    "2. Construct a `DataFrame` containing only the businesses which DO NOT have valid ZIP codes.  You will probably want to use the `Series.isin` function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Step 1**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3ci\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_bus = pd.read_json('https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/sf_zipcodes.json', dtype='str')\n",
    "valid_zips = zip_bus['zip_codes']\n",
    "valid_zips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Step 2**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3cii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_zip_bus = bus[~bus['postal_code'].isin(valid_zips)].copy()\n",
    "invalid_zip_bus.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "### Question 3d\n",
    "\n",
    "In the previous question, many of the businesses had a common invalid postal code that was likely used to encode a MISSING postal code.  Do they all share a potentially \"interesting address\"?\n",
    "\n",
    "In the following cell, construct a **series** that counts the number of businesses at each `address` that have this single likely MISSING postal code value.  Order the series in descending order by count. \n",
    "\n",
    "After examining the output.  Answer the following question by filling in the appropriate variable. If we were to drop businesses with MISSING postal code values would a particular class of business be affected?  If you are unsure try to search the web for the most common addresses.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3d\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "address\n",
       "001 WEST PORTAL Ave        0\n",
       "0044 Montgomery St  LL1    0\n",
       "022 Battery St             0\n",
       "0239 BALBOA St             0\n",
       "0259 Kearny St             0\n",
       "0264 Kearny St             0\n",
       "033 WEST PORTAL Ave        0\n",
       "0427 CASTRO St             0\n",
       "0436 BALBOA St             0\n",
       "045 CASTRO St              0\n",
       "050 WEST PORTAL Ave        0\n",
       "052 California St          0\n",
       "0530 BALBOA St             0\n",
       "0537 BALBOA St             0\n",
       "054 WEST PORTAL Ave        0\n",
       "0600 GUERRERO St           0\n",
       "069 WEST PORTAL Ave        0\n",
       "0703 GUERRERO St           0\n",
       "085 WEST PORTAL Ave        0\n",
       "0994 GUERRERO St           0\n",
       "Name: missing_postal_code, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_zip_address_count = bus['missing_postal_code'] = bus['postal_code'].isnull()\n",
    "missing_zip_address_count = bus.groupby(['address'])['missing_postal_code'].sum()\n",
    "missing_zip_address_count.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3e\n",
    "\n",
    "**True or False**:  *If we were to drop businesses with MISSING postal code values, a particular class of business will be affected.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3e\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True or False: \n",
    "#  If we were to drop businesses with MISSING postal code values \n",
    "#   a particular class of business be affected.\n",
    "q3d_true_or_false = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3f\n",
    "\n",
    "Examine the `invalid_zip_bus` dataframe we computed above and look at the businesses that DO NOT have the special MISSING ZIP code value.  Some of the invalid postal codes are just the full 9 digit code rather than the first 5 digits.  Create a new column named `postal5` in the original `bus` dataframe which contains only the first 5 digits of the `postal_code` column.   Finally, for any of the `postal5` ZIP code entries that were not a valid San Fransisco ZIP Code (according to `valid_zips`) set the entry to `None`.  \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3f\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>postal5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100126</td>\n",
       "      <td>Lamas Peruvian Food Truck</td>\n",
       "      <td>-9999</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>100417</td>\n",
       "      <td>COMPASS ONE, LLC</td>\n",
       "      <td>94105-1420</td>\n",
       "      <td>94105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>100660</td>\n",
       "      <td>TEAPENTER</td>\n",
       "      <td>94122-1909</td>\n",
       "      <td>94122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>100781</td>\n",
       "      <td>LE CAFE DU SOLEIL</td>\n",
       "      <td>94117-3504</td>\n",
       "      <td>94117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>101084</td>\n",
       "      <td>Deli North 200</td>\n",
       "      <td>94518</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>99369</td>\n",
       "      <td>HOTEL BIRON</td>\n",
       "      <td>94102-5917</td>\n",
       "      <td>94102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>99376</td>\n",
       "      <td>Mashallah Halal Food truck Ind</td>\n",
       "      <td>-9999</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>99536</td>\n",
       "      <td>FAITH SANDWICH #2</td>\n",
       "      <td>94105-2907</td>\n",
       "      <td>94105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>99681</td>\n",
       "      <td>Twister</td>\n",
       "      <td>95112</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6241</th>\n",
       "      <td>99819</td>\n",
       "      <td>CHESTNUT DINER</td>\n",
       "      <td>94123-3106</td>\n",
       "      <td>94123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bid                            name postal_code postal5\n",
       "22    100126       Lamas Peruvian Food Truck       -9999    None\n",
       "68    100417                COMPASS ONE, LLC  94105-1420   94105\n",
       "96    100660                       TEAPENTER  94122-1909   94122\n",
       "109   100781               LE CAFE DU SOLEIL  94117-3504   94117\n",
       "144   101084                  Deli North 200       94518    None\n",
       "...      ...                             ...         ...     ...\n",
       "6173   99369                     HOTEL BIRON  94102-5917   94102\n",
       "6174   99376  Mashallah Halal Food truck Ind       -9999    None\n",
       "6199   99536               FAITH SANDWICH #2  94105-2907   94105\n",
       "6204   99681                         Twister       95112    None\n",
       "6241   99819                  CHESTNUT DINER  94123-3106   94123\n",
       "\n",
       "[230 rows x 4 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus['postal5'] = bus['postal_code'].str[:5]\n",
    "bus['postal5'] = bus['postal5'].where(bus['postal5'].isin(valid_zips), None)\n",
    "\n",
    "# Checking the corrected postal5 column\n",
    "bus.loc[invalid_zip_bus.index, ['bid', 'name', 'postal_code', 'postal5']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Linear Regression \n",
    "In this part of the assignment, you will use what you've learned in class to fit a regression model. The ``LinearRegression`` estimator is much more capable to handle multidimensional linear models of the form\n",
    "$$\n",
    "y = a_0 + a_1 x_1 + a_2 x_2 + \\cdots\n",
    "$$\n",
    "where there are multiple $x$ values.\n",
    "Geometrically, this is akin to fitting a plane to points in three dimensions, or fitting a hyper-plane to points in higher dimensions.\n",
    "\n",
    "The multidimensional nature of such regressions makes them more difficult to visualize. We can use the single ``LinearRegression`` estimator to fit lines, planes, or hyperplanes to our data. It still appears that this approach would be limited to strictly linear relationships between variables, but it turns out we can relax this as well.\n",
    "\n",
    "### Loading the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDIECdJPXxOQ"
   },
   "source": [
    "In the English Premier League,  May - July represents a lull period due to the lack of club football. What makes up for it, is the intense transfer speculation that surrounds all major player transfers today. An important part of negotiations is predicting the fair market price for a player. You are tasked with predicting this Market Value of a player using the data provided below\n",
    "\n",
    "The attached data set consists of the following attributes:\n",
    "\n",
    "*  name: Name of the player\n",
    "*  club: Club of the player\n",
    "*  age : Age of the player\n",
    "*  position : The usual position on the pitch\n",
    "*  position_cat: 1 for attackers, 2 for midfielders, 3 for defenders, 4 for goalkeepers\n",
    "*  market_value : As on transfermrkt.com on July 20th, 2017\n",
    "*  page_views : Average daily Wikipedia page views from September 1, 2016 to May 1, 2017\n",
    "*  fpl_value : Value in Fantasy Premier League as on July 20th, 2017\n",
    "*  fpl_sel : % of FPL players who have selected that player in their team\n",
    "*  fpl_points : FPL points accumulated over the previous season\n",
    "*  region: 1 for England, 2 for EU, 3 for Americas, 4 for Rest of World\n",
    "*  nationality\n",
    "*  new_foreign : Whether a new signing from a different league, for 2017/18 (till 20th July)\n",
    "*  age_cat\n",
    "*  club_id\n",
    "*  big_club: Whether one of the Top 6 clubs\n",
    "*  new_signing: Whether a new signing for 2017/18 (till 20th July)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "hGWfXWC_WyJo",
    "outputId": "63651dcc-a0e3-4481-c1d9-d3bcd94c00a1"
   },
   "outputs": [],
   "source": [
    "football = pd.read_csv('https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/football.csv')\n",
    "football.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4\n",
    "Drop columns named `'name','fpl_sel','position','nationality','region','new_foreign'` from `football` dataframe.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "D9MUWrGF5B-N",
    "outputId": "cf5282c0-fb39-4f99-ed10-bb10c2098865"
   },
   "outputs": [],
   "source": [
    "football = football.drop(columns=['name','fpl_sel','position','nationality','region','new_foreign'])\n",
    "football.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Let's look at the shape of the updated football data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of Data: ', football.shape)\n",
    "print('data.describe:')\n",
    "football.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5\n",
    "Define the function `correlation` which computes the correlation of dataframe variables and returns the result. \n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataframe):\n",
    "    return dataframe.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6 \n",
    "Let's do some visualization to: \n",
    "\n",
    "a) Find the correlation between variables of `football` dataset using `correlation` function defined above, to create a heatmap.\n",
    "\n",
    "b) Create a barplot of `age` vs `market_value`.\n",
    "\n",
    "c) Create a barplot of `position_cat` vs `market_value`.\n",
    "\n",
    "d) Create a barplot of `big_club` vs `market_value`.\n",
    "\n",
    "e) Create a barplot of `club` vs `market_value`.\n",
    "\n",
    "f) Create a scatterplot of `page_views` vs `market_value`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6\n",
    "manual: true\n",
    "points: 6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "vWIYBUbp9aH_",
    "outputId": "037b3ba2-7819-4a4a-95d1-7fa221632c98"
   },
   "outputs": [],
   "source": [
    "# Part a)\n",
    "corr = correlation(football)\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(240,10,as_cmap=True),\n",
    "            square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "IB9RaA03CJ9i",
    "outputId": "9eac8ba4-296a-4e69-816d-dcb5f3c08d91"
   },
   "outputs": [],
   "source": [
    "# Part b)\n",
    "...\n",
    "print('Market Value vs Age')\n",
    "sns.barplot(data=football, x='age', y='market_value')\n",
    "print('The age group of 22 to 29 have the most market value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "5_CAmYcm_IHV",
    "outputId": "de80f974-a475-4153-f7a7-ed208bdf0706"
   },
   "outputs": [],
   "source": [
    "# Part c)\n",
    "...\n",
    "print('Market Value vs Position Cat')\n",
    "sns.barplot(data=football, x='position_cat', y='market_value')\n",
    "print('The Position Cat 1 has the most market value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "DoQB7Iizzfv0",
    "outputId": "fb737862-e465-4556-f055-82d6b594a44e"
   },
   "outputs": [],
   "source": [
    "# Part d)\n",
    "...\n",
    "print('Market Value vs Big Club')\n",
    "sns.barplot(data=football, x='big_club', y='market_value')\n",
    "print('We see that the market value of players from the top 6 clubs is significantly higher than the other players.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "hLLne2RgF0ke",
    "outputId": "ae636651-e687-4973-8eeb-cc17f80afd85"
   },
   "outputs": [],
   "source": [
    "# Part e)\n",
    "ax = sns.barplot(data=football, x='club', y='market_value')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=80)\n",
    "print('Market Value vs Club')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "9aIBYnWRLpM-",
    "outputId": "83465c31-9bde-43c6-d951-1845f54044e9"
   },
   "outputs": [],
   "source": [
    "# Part f)\n",
    "sns.scatterplot(data=football, x='market_value', y='page_views')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BUj3EKrdl8O"
   },
   "source": [
    "### Training Validation Split\n",
    "Now, split the data into train and test datasets. The training data is used to fit the model and test data is used to assess the performance of your model. Note that the seed is set to (random_state) to 42. This will produce a pseudo-random sequence of random numbers that is the same for every student. **Do not modify this in the following questions, as our tests depend on this random seed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_test_split(football, test_size = 0.25, random_state= 42)\n",
    "display(x_train)\n",
    "display(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, we split the data, drop `club` column from `football` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E08sWGhFOA0s"
   },
   "outputs": [],
   "source": [
    "# Dropping a column from the dataset\n",
    "football = football.drop(columns=['club'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_variable = 'market_value'\n",
    "train_reg, test_reg = train_test_split(football, test_size = 0.25, random_state= 42) \n",
    "X_train_reg = train_reg[train_reg.columns[~train_reg.columns.isin([response_variable])]]\n",
    "y_train_reg = train_reg[[response_variable]]\n",
    "X_test_reg = test_reg[test_reg.columns[~ test_reg.columns.isin([response_variable])]]\n",
    "y_test_reg = test_reg[[response_variable]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Now that we have matrices, we can build a regression model with `scikit-learn`! Using the [`LinearRegression`] estimator, fit a regression model using `X_train_reg` and `y_train_reg`. Then, output the model's training accuracy below. You should get an training accuracy of around $0.74$ and test accuracy of around $0.80$.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXytP0bJIZzR",
    "outputId": "634bf70a-2af3-4a3c-e680-4f4a40f6fd98"
   },
   "outputs": [],
   "source": [
    "reg_model = linear_model.LinearRegression()\n",
    "...\n",
    "reg_model.fit(X_train_reg, y_train_reg)\n",
    "y_train_pred = reg_model.predict(X_train_reg)\n",
    "\n",
    "training_accuracy = reg_model.score(X_train_reg, y_train_reg)\n",
    "test_accuracy = reg_model.score(X_test_reg, y_test_reg)\n",
    "\n",
    "print ('Regression: R^2 score on training set', training_accuracy)\n",
    "print ('Regression: R^2 score on test set', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 8\n",
    "\n",
    "Create a dataframe of `y_test_reg` (actual), `predicted values` (predicted), and `residual`. Then create a `lmplot` (actualv vs predicted values). \n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8\n",
    "manual: true\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "id": "PhSXupNqerdp",
    "outputId": "6fe16138-3483-48ac-eb4c-0359223f53f1"
   },
   "outputs": [],
   "source": [
    "y_pred = reg_model.predict(X_test_reg)\n",
    "y_pred_reshaped = y_pred.reshape(-1)\n",
    "residual_df = pd.DataFrame({'actual': y_test_reg.values.flatten(), \n",
    "                            'predicted': y_pred_reshaped, \n",
    "                            'residual': y_test_reg.values.flatten() - y_pred_reshaped})\n",
    "sns.lmplot(x='actual', y='predicted', data=residual_df)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 9\n",
    "\n",
    "Also, calculate and print the Root Mean Square Error for the regression model fitted above.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q9\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean((y_test_reg.values - y_pred) ** 2))\n",
    "print(\"Root Mean Square Error: \", rmse) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Part 3: Spam/Ham Classification\n",
    "### Feature Engineering, Logistic Regression, Cross Validation\n",
    "In this part of the assignment, you will use what you've learned in class to fit a classifier that can distinguish spam (junk or commercial or bulk) emails from ham (non-spam) emails. In addition to providing some skeleton code to fill in, we will evaluate your work based on your model's accuracy and your written responses in this notebook. This assignment section will cover the following concepts:\n",
    "\n",
    "- Feature engineering with text data\n",
    "- Using `sklearn` libraries to process data and fit classification models\n",
    "- Validating the performance of your model and minimizing overfitting\n",
    "- Generating and analyzing precision-recall curves\n",
    "  \n",
    "**Caution:**\n",
    "This is a **real world** dataset – the emails you are trying to classify are actual spam and legitimate emails. As a result, some of the spam emails may be in poor taste or be considered inappropriate. The benefit of working with realistic data outweighs these innapropriate emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loading",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Loading in the Data\n",
    "\n",
    "In email classification, the goal is to classify emails as spam or not spam (referred to as \"ham\") using features generated from the text in the email. \n",
    "\n",
    "The dataset consists of email messages and their labels (0 for ham, 1 for spam). Your labeled training dataset contains 8348 labeled examples, and the unlabeled test set contains 1000 unlabeled examples.\n",
    "\n",
    "Run the following cells to load in the data into Dataframe.\n",
    "\n",
    "The `train` DataFrame contains labeled data that you will use to train your model. It contains four columns:\n",
    "\n",
    "1. `id`: An identifier for the training example\n",
    "1. `subject`: The subject of the email\n",
    "1. `email`: The text of the email\n",
    "1. `spam`: 1 if the email is spam, 0 if the email is ham (not spam)\n",
    "\n",
    "The `test` DataFrame contains 1000 unlabeled emails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.181245Z",
     "start_time": "2019-04-03T20:17:41.343927Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "fetch-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "original_training_data = pd.read_csv('https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/spam_data/train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/sukhjitsehra/datasets/master/CP322/spam_data/test.csv')\n",
    "\n",
    "# Convert the emails to lower case as a first step to processing the text\n",
    "original_training_data['email'] = original_training_data['email'].str.lower()\n",
    "test['email'] = test['email'].str.lower()\n",
    "\n",
    "original_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34476156ed73b800",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 10a\n",
    "First, let's check if our data contains any missing values. Fill in the cell below to print the number of NaN values in each column. If there are NaN values, replace them with appropriate filler values (i.e., NaN values in the `subject` or `email` columns should be replaced with empty strings). Print the number of NaN values in each column after this modification to verify that there are no NaN values left.\n",
    "\n",
    "Note that while there are no NaN values in the `spam` column, we should be careful when replacing NaN labels. Doing so without consideration may introduce significant bias into our model when fitting.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.203231Z",
     "start_time": "2019-04-03T20:17:42.185104Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1fb39d9b651ca1b",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "print('Before imputation:') \n",
    "print(original_training_data.isnull().sum()) \n",
    "# fill in the missing values and update the original_training_data\n",
    "original_training_data = original_training_data.fillna('')\n",
    "print('------------')\n",
    "print('After imputation:')\n",
    "print(original_training_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 10b\n",
    "\n",
    "In the cell below, print the text of the `email` field for the first ham and the first spam email in the original training set.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.247245Z",
     "start_time": "2019-04-03T20:17:42.228451Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "first_ham = original_training_data[original_training_data['spam'] == 0]['email'].iloc[0]\n",
    "first_spam = original_training_data[original_training_data['spam'] == 1]['email'].iloc[0]\n",
    "print(first_ham)\n",
    "print(first_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 10c\n",
    "\n",
    "Discuss one thing you notice that is different between the two emails that might relate to the identification of spam.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10c\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_One difference between the two emails that might relate to the identification of spam is the format. The first email is written in plain text, while the second email is written in HTML. The use of HTML, specifically with font size changes and hyperlinks, is a common tactic used by spammers to make the email more visually appealing and encourage the recipient to click on links that might lead to malicious websites. The plain text format of the first email, on the other hand, is less likely to contain malicious content._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-78513403ef52a957",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### Training Validation Split\n",
    "The training data downloaded is available for both training models and **validating** the models.  Therefore, you must it to separate training and validation datsets.  The **validation data** is used to assess the performance of your classifier once you are finished training. Note that the seed is set to (random_state) to 42. This will produce a pseudo-random sequence of random numbers that is the same for every student. **Do not modify this in the following questions, as our tests depend on this random seed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.317970Z",
     "start_time": "2019-04-03T20:17:42.294532Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-873194ed3e686dfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This creates a 90/10 train-validation split on our labeled data\n",
    "\n",
    "train, val = train_test_split(original_training_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "feat-eng",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Basic Feature Engineering\n",
    "\n",
    "We would like to take the text of an email and predict whether the email is ham or spam. This is a *classification* problem, so we can use logistic regression to train a classifier. Recall that to train an logistic regression model we need a numeric feature matrix $X$ and a vector of corresponding binary labels $y$.  Unfortunately, our data are text, not numbers. To address this, we can create numeric features derived from the email text and use those features for logistic regression.\n",
    "\n",
    "Each row of $X$ is an email. Each column of $X$ contains one feature for all the emails. We'll guide you through creating a simple feature, and you'll create more interesting ones as you try to increase the accuracy of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 11\n",
    "\n",
    "Create a function called `words_in_texts` that takes in a list of `words` and a pandas Series of email `texts`. It should output a 2-dimensional NumPy array containing one row for each email text. The row should contain either a 0 or a 1 for each word in the list: 0 if the word doesn't appear in the text and 1 if the word does. For example:\n",
    "\n",
    "```\n",
    ">>> words_in_texts(['hello', 'bye', 'world'], \n",
    "                   pd.Series(['hello', 'hello worldhello']))\n",
    "\n",
    "array([[1, 0, 0],\n",
    "       [1, 0, 1]])\n",
    "```\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q11\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.337281Z",
     "start_time": "2019-04-03T20:17:42.320567Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0], [1, 0, 1]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    '''\n",
    "    Args:\n",
    "        words (list): words to find\n",
    "        texts (Series): strings to search in\n",
    "    \n",
    "    Returns:\n",
    "        NumPy array of 0s and 1s with shape (n, p) where n is the\n",
    "        number of texts and p is the number of words.\n",
    "    '''\n",
    "    indicator_array = []\n",
    "    for text in texts:\n",
    "        row = []\n",
    "        for word in words:\n",
    "            if word in text:\n",
    "                row.append(1)\n",
    "            else:\n",
    "                row.append(0)\n",
    "        indicator_array.append(row)\n",
    "    return indicator_array\n",
    "\n",
    "words_in_texts(['hello', 'bye', 'world'], \n",
    "                   pd.Series(['hello', 'hello worldhello']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "eda",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We need to identify some features that allow us to distinguish spam emails from ham emails. One idea is to compare the distribution of a single feature in spam emails to the distribution of the same feature in ham emails. If the feature is itself a binary indicator, such as whether a certain word occurs in the text, this amounts to comparing the proportion of spam emails with the word to the proportion of ham emails with the word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.428419Z",
     "start_time": "2019-04-03T20:17:42.386697Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "df = pd.DataFrame({\n",
    "    'word_1': [1, 0, 1, 0],\n",
    "    'word_2': [0, 1, 0, 1],\n",
    "    'type': ['spam', 'ham', 'ham', 'ham']\n",
    "})\n",
    "display(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\n",
    "display(df);\n",
    "display(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\n",
    "display(df.melt(\"type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 12\n",
    "Create a bar chart like the one above comparing the proportion of spam and ham emails containing certain words. Choose a set of words that are different from the ones above, but also have different proportions for the two classes. Please ensure to only consider emails from `train`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q12\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.145246Z",
     "start_time": "2019-04-03T20:17:42.430406Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q3a-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n",
    "some_words = ['opportunity', 'bank', 'receive', 'dear', 'best', 'deal']\n",
    "Phi_train = []\n",
    "for text in train['email']:\n",
    "    phi = []\n",
    "    for word in some_words:\n",
    "        if word in text:\n",
    "            phi.append(1)\n",
    "        else:\n",
    "            phi.append(0)\n",
    "    Phi_train.append(phi)\n",
    "\n",
    "df = pd.DataFrame(Phi_train, columns=some_words)\n",
    "\n",
    "df['label'] = train['spam']\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x = \"variable\", \n",
    "            y = \"value\", \n",
    "            hue = \"label\", \n",
    "            data = (df\n",
    "                    .replace({'label': \n",
    "                                {0 : 'Ham', \n",
    "                                 1 : 'Spam'}})\n",
    "                    .melt('label')\n",
    "                    .groupby(['label', 'variable'])\n",
    "                    .mean()\n",
    "                    .reset_index()))\n",
    "\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Proportion of Emails')\n",
    "plt.legend(title = \"\")\n",
    "plt.title(\"Frequency of Words in Spam/Ham Emails\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "When the feature is binary, it makes sense to compare its proportions across classes (as in the previous question). Otherwise, if the feature can take on numeric values, we can compare the distributions of these values for different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "classification",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Fit the classification model\n",
    "\n",
    "Notice that the output of `words_in_texts(words, train['email'])` is a numeric matrix containing features for each email. This means we can use it directly to train a classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 13\n",
    "\n",
    "You have given you 5 words that might be useful as features to distinguish spam/ham emails. Use these words as well as the `train` DataFrame to create two NumPy arrays: `X_train` and `Y_train`.\n",
    "\n",
    "`X_train` should be a matrix of 0s and 1s created by using your `words_in_texts` function on all the emails in the training set.\n",
    "\n",
    "`Y_train` should be a vector of the correct labels for each email in the training set.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q13\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.726012Z",
     "start_time": "2019-04-03T20:17:43.498088Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q4-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n",
    "\n",
    "X_train = words_in_texts(some_words, train['email'])\n",
    "Y_train = train['spam'].to_numpy()\n",
    "\n",
    "X_train[:5], Y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 14\n",
    "\n",
    "Now that we have matrices, we can build a model with `scikit-learn`! Using the [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier, train a logistic regression model using `X_train` and `Y_train`. Then, output the model's training accuracy below. You should get an accuracy of around $0.75$\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q14\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:44.593918Z",
     "start_time": "2019-04-03T20:17:43.783872Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q5-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression().fit(X_train, Y_train)\n",
    "...\n",
    "\n",
    "training_accuracy = model.score(X_train, Y_train)\n",
    "print(\"Training Accuracy: \", training_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier you made above isn't as good as the accuracy would make you believe. First, we are evaluating accuracy on the training set, which may provide a misleading accuracy measure. Accuracy on the training set doesn't always translate to accuracy in the real world (on the test set). In future parts of this analysis, we will hold out some of our data for model validation and comparison.\n",
    "\n",
    "Presumably, our classifier will be used for **filtering**, i.e. preventing messages labeled `spam` from reaching someone's inbox. There are two kinds of errors we can make:\n",
    "- False positive (FP): a ham email gets flagged as spam and filtered out of the inbox.\n",
    "- False negative (FN): a spam email gets mislabeled as ham and ends up in the inbox.\n",
    "\n",
    "To be clear, we label spam emails as 1 and ham emails as 0. These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier, in addition to overall accuracy:\n",
    "\n",
    "**Precision** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ of emails flagged as spam that are actually spam.\n",
    "\n",
    "**Recall** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$ of spam emails that were correctly flagged as spam. \n",
    "\n",
    "**False-alarm rate** measures the proportion $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$ of ham emails that were incorrectly flagged as spam. \n",
    "\n",
    "The two graphics below may help you understand precision and recall visually:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\" width=\"500px\">\n",
    "\n",
    "Note that a true positive (TP) is a spam email that is classified as spam, and a true negative (TN) is a ham email that is classified as ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 15a\n",
    "\n",
    "Suppose we have a classifier `zero_predictor` that always predicts 0 (never predicts positive). How many false positives and false negatives would this classifier have if it were evaluated on the training set and its results were compared to `Y_train`? Fill in the variables below (feel free to hard code your answers for this part):\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q15a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:20:13.853633Z",
     "start_time": "2019-04-03T20:20:13.825724Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# give your hard coded answers below for the values of False Positives and False Negatives\n",
    "zero_predictor_fp = len(train[train['spam'] == 1])\n",
    "zero_predictor_fn = 0\n",
    "zero_predictor_fp, zero_predictor_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 15b\n",
    "\n",
    "What is the accuracy and recall of `zero_predictor` (classifies every email as ham) on the training set? Do **NOT** use any `sklearn` functions.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q15b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:23:21.553134Z",
     "start_time": "2019-04-03T20:23:21.548219Z"
    }
   },
   "outputs": [],
   "source": [
    "zero_predictor_acc = len(train[train['spam'] == 0]) / len(train)\n",
    "zero_predictor_recall = 0\n",
    "zero_predictor_acc, zero_predictor_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 15c\n",
    "\n",
    "Compute the precision, recall, and false-alarm rate of the `LogisticRegression` classifier created and trained in Question 14. Do **NOT** use any `sklearn` functions.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q15c\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:37:54.875265Z",
     "start_time": "2019-04-03T20:37:54.720667Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train_pred = model.predict(X_train)\n",
    "\n",
    "TP = np.sum((Y_train==1) & (Y_train_pred==1))\n",
    "TN = np.sum((Y_train==0) & (Y_train_pred==0))\n",
    "FP = np.sum((Y_train==0) & (Y_train_pred==1))\n",
    "FN = np.sum((Y_train==1) & (Y_train_pred==0))\n",
    "\n",
    "logistic_predictor_precision = TP / (TP + FP)\n",
    "logistic_predictor_recall = TP / (TP + FN)\n",
    "logistic_predictor_far = FP / (TN + FP)\n",
    "\n",
    "print(\"Precision: \", logistic_predictor_precision)\n",
    "print(\"Recall: \", logistic_predictor_recall)\n",
    "print(\"False Alarm Rate: \", logistic_predictor_far)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 15d\n",
    "\n",
    "1. How does fitted model's prediction accuracy (number of correct predictions / total) is compared with predicting 0 for every email?\n",
    "2. Given the word features given above, name one reason this classifier is performing poorly. Hint: Think about how prevalent these words are in the email set.\n",
    "3. Which of these two classifiers would you prefer for a spam filter and why? Describe your reasoning and relate it to at least one of the evaluation metrics you have computed so far.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q15d\n",
    "manual: True\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- The fitted model's prediction accuracy is likely to be higher compared to predicting 0 for every email as it is using the word features to make predictions about the email labels, whereas always predicting 0 will result in a low accuracy rate.\n",
    "\n",
    "2- One reason the classifier is performing poorly is that the word features used are not very specific to spam emails. For example, the word \"bank\" is present in both spam and ham emails, so it is not a reliable feature to differentiate between the two.\n",
    "\n",
    "3- For a spam filter, I would prefer the fitted logistic regression model. While it may not have a high accuracy, it is still better than always predicting 0. Additionally, the precision of the model is relatively high, which means that the model is good at not classifying ham emails as spam. This is important because falsely marking ham emails as spam can be very disruptive to the user."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
